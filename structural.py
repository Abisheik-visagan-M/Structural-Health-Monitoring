# -*- coding: utf-8 -*-
"""structural.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mnyu5yXwfWvePld7XcmJ6fpJUetzbxpJ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score
from sklearn.utils.class_weight import compute_class_weight

# Set the seed for reproducibility
np.random.seed(42)

# Generate timestamps
timestamps = pd.date_range(start='2023-01-01', periods=5000, freq='H')

# Generate synthetic data with more variability and noise
vibration = np.random.normal(loc=5, scale=1.5, size=len(timestamps))  # Normal vibrations with more variability
stress = np.random.normal(loc=50, scale=7, size=len(timestamps))    # Normal stress with more variability
temperature = np.random.normal(loc=25, scale=5, size=len(timestamps))  # Temperature variations
humidity = np.random.normal(loc=60, scale=10, size=len(timestamps))  # Humidity variations
traffic_load = np.random.normal(loc=300, scale=75, size=len(timestamps))  # Traffic load variations

# Introduce periodic noise
periodic_noise = np.sin(np.linspace(0, 20 * np.pi, len(timestamps))) * 2
vibration += periodic_noise
stress += periodic_noise

# Introduce more varied and subtle anomalies
anomaly_indices = np.random.choice(len(timestamps), size=300, replace=False)
vibration[anomaly_indices] += np.random.normal(loc=10, scale=7, size=300)  # High vibrations indicating potential issues
stress[anomaly_indices] += np.random.normal(loc=20, scale=15, size=300)  # High stress
temperature[anomaly_indices] += np.random.normal(loc=10, scale=5, size=300)  # Unusual temperatures
humidity[anomaly_indices] += np.random.normal(loc=20, scale=10, size=300)  # Unusual humidity
traffic_load[anomaly_indices] += np.random.normal(loc=200, scale=100, size=300)  # Unusual traffic load

# Health status based on anomalies
health_status = np.zeros(len(timestamps))
health_status[anomaly_indices] = 1

# Create a DataFrame
data = pd.DataFrame({
    'Timestamp': timestamps,
    'Vibration': vibration,
    'Stress': stress,
    'Temperature': temperature,
    'Humidity': humidity,
    'Traffic_Load': traffic_load,
    'Health_Status': health_status
})

# Save the data to a CSV file
data.to_csv('structural_health_data.csv', index=False)

# Load the data
data = pd.read_csv('structural_health_data.csv')

# Check for missing values
print(data.isnull().sum())

# Feature scaling
scaler = StandardScaler()
data[['Vibration', 'Stress', 'Temperature', 'Humidity', 'Traffic_Load']] = scaler.fit_transform(data[['Vibration', 'Stress', 'Temperature', 'Humidity', 'Traffic_Load']])

# Split the data into features and target
X = data[['Vibration', 'Stress', 'Temperature', 'Humidity', 'Traffic_Load']]
y = data['Health_Status']

# Compute class weights to handle imbalance
class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)
class_weight_dict = dict(zip(np.unique(y), class_weights))

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Initialize Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10, min_samples_leaf=5, class_weight=class_weight_dict, random_state=42)

# Hyperparameter tuning using RandomizedSearchCV (faster than GridSearchCV)
param_dist = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 5],
    'bootstrap': [True, False]
}

random_search = RandomizedSearchCV(rf_model, param_dist, n_iter=10, cv=5, scoring='roc_auc', n_jobs=-1, random_state=42)
random_search.fit(X_train, y_train)

# Best model from RandomizedSearchCV
best_rf_model = random_search.best_estimator_

# Train the model on the entire training set
best_rf_model.fit(X_train, y_train)

# Make predictions
y_pred = best_rf_model.predict(X_test)
y_pred_proba = best_rf_model.predict_proba(X_test)[:, 1]

# Evaluate the model
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_proba)
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc_value = auc(fpr, tpr)

# Display results
print("Confusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(class_report)
print(f"\nAUC-ROC: {roc_auc:.2f}")

# Plot ROC Curve
plt.figure()
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc_value:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

# Precision-Recall curve
precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
average_precision = average_precision_score(y_test, y_pred_proba)

plt.figure()
plt.plot(recall, precision, color='green', lw=2, label=f'PR curve (average precision = {average_precision:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

# Feature importance
feature_importances = best_rf_model.feature_importances_
features = X.columns
plt.barh(features, feature_importances)
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Feature Importance in Predicting Structural Health')
plt.show()

"""# New Section"""